---
layout: article
title: Bonding 네트워크 이중화
tags: [Linux, Bonding]
key: 20200909-bonding
---

> CentOS 기준으로 작성하였습니다.  
> 네트워크인터페이스카드(NIC)를 이중화 함으로써 장애를 예방할 수 있습니다.


## Bonding mode (본딩모드)

> bonding 의 6가지 모드

|mode   |명칭   |설명 |
|:---:  |:--   |:-- |
|0   |balance-rr         |・ load balancing (round-robin)<br>・모든 슬레이브 장치（NIC）를 차례（라운드로빈）로 사용 패킷을 보냅니다.<br>・ 전송만 부하분산 (로드밸런싱)<br>・ 디폴트값입니다. |
|1   |active-backup   |・ fault-tolerance (active-backup)<br>・ 하나의 NIC만  활성화 인터페이스로 보냅니다.<br>・ 송수신 둘다 부하 분산이 없습니다.<br>・ 평상시에는 하나의 NIC으로만 통신하여 통신장애가 발생하면 전환모드입니다.|
|2   |balance-xor      |・ load balancing (xor)<br>・ 송신원/대상의 MAC어드레스를 바탕으로 전송 슬레이브 디바이스를 결정해 패킷을 보냅니다.<br>・ 송신패킷만 부하분산(로드밸런싱)|
|3   |broadcast          | ・ fault-tolerance (broadcast)<br>・ 모든 슬레이브에 동일한 패킷을 보냅니다.<br>・ 일반 용도로는 사용하지 않음.|
|4   |802.3ad            |・ IEEE 802.3ad Dynamic link aggregation<br>・ IEEE 802.3ad(LACP)을 기준한 링크 어그리게이션(Link aggregation:여러개의 물리적인 회선을 가상적으로 묶어 마치 하나의 회선인것처럼 처리하는 기술로 예를 들어 1Gbps회선 5개를 가상으로 묶어 5Gbps의 가상 통신대역을 사용할수 있습니다.)<br> ・연결하는 스위치가 IEEE 802.3ad에 대응할 필요가 있습니다.|
|5   |balance-tlb       |・ transmit load balancing<br>・ 각 슬레이브의 부하에 따라 전송 슬레이브를 분산합니다. 수신은 현재 슬레이브에 의해 행해집니다.<br> ・ 송신패킷만 부하분산(로드밸런싱)|
|6   |balance-alb      |・ adaptive load balancing<br> ・ balance-tlb의 기능뿐만 아니라 송수신도 부하분산 (로드밸런싱)|

<br>

## 1. LAN card 추가

> bonding 구성하기 위해서는 최소 2개의 네트워크 인터페이스 카드(NIC)가 필요합니다.  
> 실적용이 아닌 Test 목적의 실습으로 하시려면 vmware와 같은 가상머신을 활용하시면 됩니다.

![add nic](http://drive.google.com/thumbnail?id=1DFQJKDn2smx6PdmXXKNu4Umc7KkO3DgO&sz=w1000)

<br>

## 2. /etc/sysconfig/network 내용추가

> `/etc/sysconfig/network`{:.info} 에 `gatewaydev` 를 추가합니다.  

```
$ vi /etc/sysconfig/network
```
{% highlight network linenos %}
NETWORKING=yes
HOSTNAME=myserver
GATEWAYDEV=bond0
{% endhighlight %}

<br>

## 3. bond 파일 생성

> bond 파일을 만들어 줍니다.  
> ip 는 현재 네트워크구성에 맞게 설정해 주어야 합니다.

```
$ vi /etc/sysconfig/network-scripts/ifcfg-bond0
```

{% highlight ifcfg-bond0 linenos %}
DEVICE=bond0
IPADDR=192.168.1.1
NETMASK=255.255.255.0
GATEWAY=192.168.1.254
USERCTL=no
BOOTPROTO=none
ONBOOT=yes
NM_CONTROLLED=no
TYPE=Ethernet
BONDING_OPTS="mode=1 miimon=100 use_carrier=0 primary=eth1"
{% endhighlight %}

<br>

## 4. eth1, eth2 설정 파일 생성

```
$ vi /etc/sysconfig/network-scripts/ifcfg-eth1
```
{% highlight ifcfg-eth1 linenos %}
DEVICE=eth1
ONBOOT=yes
BOOTPROTO=none
USERCTL=no
MASTER=bond0
SLAVE=yes
{% endhighlight %}

```
$ vi /etc/sysconfig/network-scripts/ifcfg-eth2
```
{% highlight ifcfg-eth2 linenos %}
DEVICE=eth2
ONBOOT=yes
BOOTPROTO=none
USERCTL=no
MASTER=bond0
SLAVE=yes
{% endhighlight %}

<br>

## 5. modprobe.conf 파일 생성 후 적용

> mode=1 (active-backup)으로 구성을 해보겠습니다.<br>
> miimon 옵션은 링크 감시 설정모드로 ms 단위를 사용하며 디폴트 값이 0(사용안함)입니다.<br>
> 즉, 0으로 설정하면 failover가 비활성화되는 부분으로 사용하며,<br>
>  기본적으로 리눅스에서는 100ms 로 사용합니다.

```
$ vi /etc/modprobe.d/bonding.conf
```

{% highlight bonding.conf linenos %}
alias bond0 bonding
options bond0 miimon=100 mode=1
{% endhighlight %}

> 적용 및 확인

```
$ modprobe bonding
$ lsmod | grep bonding
```

<br>

## 6. 네트워크 재시작

```
$ service network restart
```

<br>

## 7. 동작 확인

```
$ cat /proc/net/bonding/bond0
Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)

Bonding Mode: fault-tolerance (active-backup)
Primary Slave: eth0 (primary_reselect always)
Currently Active Slave: eth1
MII Status: up
MII Polling Interval (ms): 100
Up Delay (ms): 0
Down Delay (ms): 0

Slave Interface: eth1
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 6
Permanent HW addr: 30:67:6c:f0:16:53
Slave queue ID: 0

Slave Interface: eth2
MII Status: up
Speed: 1000 Mbps
Duplex: full
Link Failure Count: 4
Permanent HW addr: 86:f2:c3:0b:e5:a7
Slave queue ID: 0
```
